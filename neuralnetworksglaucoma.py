# -*- coding: utf-8 -*-
"""NeuralNetworksGlaucoma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JTaiuTWieEjfDHGUUDnnbSJSRHT9uBYf

# Chapter 1: Setup & Imports
"""

import os
import cv2
import zipfile
import shutil
import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models, optimizers

#Define constants
IMAGE_SIZE = (224, 224)
CLASS_LIST = ['glaucoma', 'normal']
label_map = {'glaucoma': 0, 'normal': 1}
RAW_DIR = '/content/raw_images'
RESIZED_DIR = '/content/resized_images'

"""# Chapter 2: Upload & Preprocessing"""

from google.colab import files
uploaded = files.upload()
zip_path = next(iter(uploaded))

# Define directories
if os.path.exists(RAW_DIR):
    shutil.rmtree(RAW_DIR)
os.makedirs(RAW_DIR, exist_ok=True)

if os.path.exists(RESIZED_DIR):
    shutil.rmtree(RESIZED_DIR)
os.makedirs(RESIZED_DIR, exist_ok=True)

# Decompress dataset
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(RAW_DIR)

base_dir = RAW_DIR


# Resize images
for cls in CLASS_LIST:
    src_dir = os.path.join(base_dir, cls)
    dst_cls = os.path.join(RESIZED_DIR, cls)
    os.makedirs(dst_cls, exist_ok=True)
    for fname in os.listdir(src_dir):
        src_path = os.path.join(src_dir, fname)
        img = cv2.imread(src_path)
        if img is None:
            continue
        img_resized = cv2.resize(img, IMAGE_SIZE)
        cv2.imwrite(os.path.join(dst_cls, fname), img_resized)

"""# Chapter 3: Prepare Data"""

X, y = [], []
for cls in CLASS_LIST:
    cls_dir = os.path.join(RESIZED_DIR, cls)
    for fname in os.listdir(cls_dir):
        img_path = os.path.join(cls_dir, fname)
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, IMAGE_SIZE)
        X.append(img / 255.0)
        y.append(label_map[cls])

X = np.array(X)
y = np.array(y)

X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.10, random_state=42, stratify=y)
X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1111, random_state=42, stratify=y_trainval)

"""# Chapter 4: Visualizations"""

samples_per_class = 4
fig, axes = plt.subplots(len(CLASS_LIST), samples_per_class, figsize=(samples_per_class*3, len(CLASS_LIST)*3))
for i, cls in enumerate(CLASS_LIST):
    cls_dir = os.path.join(RESIZED_DIR, cls)
    sample_files = random.sample(os.listdir(cls_dir), samples_per_class)
    for j, fname in enumerate(sample_files):
        img = cv2.imread(os.path.join(cls_dir, fname))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        axes[i, j].imshow(img)
        axes[i, j].axis('off')
        if j == 0:
            axes[i, j].set_ylabel(cls, fontsize=12)
plt.suptitle("Sample Images per Class", fontsize=16)
plt.tight_layout()
plt.show()

samples_per_class = 150  # number random images per class
bins = 50

plt.figure(figsize=(12, 5))
for i, cls in enumerate(CLASS_LIST):
    # Collect pixels from samples_per_class random images
    cls_dir = os.path.join(RESIZED_DIR, cls)
    files = random.sample(os.listdir(cls_dir), min(samples_per_class, len(os.listdir(cls_dir))))
    pixels = []
    for fname in files:
        img = cv2.imread(os.path.join(cls_dir, fname), cv2.IMREAD_GRAYSCALE)
        pixels.extend(img.ravel())
    # Plot
    plt.subplot(1, 2, i+1)
    sns.histplot(pixels, bins=bins, kde=False)
    plt.title(f"Histogram of Pixel Intensities\n({cls}, n={len(pixels)})")
    plt.xlabel("Pixel value")
    plt.ylabel("Frequency")

plt.tight_layout()
plt.show()

"""# CNN"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# CNN structure
model_cnn = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(128, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Conv2D(256, (3, 3), activation='relu'),
    BatchNormalization(),
    MaxPooling2D(2, 2),

    Flatten(),
    Dense(256, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

#  Compile
model_cnn.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-6),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# EarlyStopping
early_stop = EarlyStopping(
    monitor='val_loss',
    patience=4,
    restore_best_weights=True
)


# Train
history_cnn = model_cnn.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=16,
    callbacks=[early_stop]
)

# Validation
val_loss, val_acc = model_cnn.evaluate(X_val, y_val)
print(f"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}")

test_loss, test_acc = model_cnn.evaluate(X_test, y_test)
print(f" Test Accuracy (CNN): {test_acc:.4f}")
print(f" Test Loss(CNN): {test_loss:.4f}")

"""# VGG16"""

from tensorflow.keras.applications import VGG16
from tensorflow.keras import models, layers, optimizers
from tensorflow.keras.callbacks import EarlyStopping

#  Load the VGG16 base model without the top classifier layers
base_model = VGG16(
    include_top=False,            # We exclude the top Dense layers
    weights='imagenet',           # Use pretrained weights
    input_shape=(224, 224, 3)     # Input shape for our images
)

#  Freeze the base model to prevent weight updates during training
base_model.trainable = False

#  Add custom classification head on top
model_vgg = models.Sequential([
    base_model,
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')   # Binary classification
])

#  Compile the model
model_vgg.compile(
    optimizer=optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

#  Setup EarlyStopping to prevent overfitting
early_stop_vgg = EarlyStopping(
    patience=3,
    restore_best_weights=True,
    monitor='val_loss'
)

#  Train the model
history_vgg = model_vgg.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=15,
    batch_size=16,
    callbacks=[early_stop_vgg]
)

#  Evaluate on validation set
val_loss, val_acc = model_vgg.evaluate(X_val, y_val)
print(f" Validation Loss : {val_loss:.4f}")
print(f" Validation Accuracy : {val_acc:.4f}")

#  Evaluate on test set
test_loss, test_acc = model_vgg.evaluate(X_test, y_test)
print(f"\n Test Accuracy (VGG16): {test_acc:.4f}")
print(f" Test Loss (VGG16): {test_loss:.4f}")

"""# MobileNetV2"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import models, layers, optimizers
from tensorflow.keras.callbacks import EarlyStopping

# Load base model
base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
base_model.trainable = False

# Build model
model_mobilenet = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(1, activation='sigmoid')
])

# Compile
model_mobilenet.compile(
    optimizer=optimizers.Adam(learning_rate=1e-4),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Early stopping
early_stop_mobilenet = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train
history_mobilenet = model_mobilenet.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=16,
    callbacks=[early_stop_mobilenet]
)

#  Evaluate on validation set
val_loss, val_acc = model_mobilenet.evaluate(X_val, y_val)
print(f" Validation Loss (MobileNetV2): {val_loss:.4f}")
print(f" Validation Accuracy (MobileNetV2): {val_acc:.4f}")

#  Evaluate on test set
test_loss, test_acc = model_mobilenet.evaluate(X_test, y_test)
print(f"\n Test Accuracy (MobileNetV2): {test_acc:.4f}")
print(f" Test Loss (MobileNetV2): {test_loss:.4f}")

"""# Evaluation CNN

"""

from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Accuracy & Loss plots
plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')
plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('CNN - Accuracy')
plt.show()

plt.plot(history_cnn.history['loss'], label='Train Loss', color='red')
plt.plot(history_cnn.history['val_loss'], label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('CNN - Loss')
plt.show()

# Predictions
y_pred = model_cnn.predict(X_val)
y_pred_labels = (y_pred > 0.5).astype(int)

print("CNN - Classification Report:")
print(classification_report(y_val, y_pred_labels))

cm = confusion_matrix(y_val, y_pred_labels)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("CNN - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

fpr, tpr, _ = roc_curve(y_val, y_pred)
auc = roc_auc_score(y_val, y_pred)
print(f"CNN AUC: {auc:.4f}")
plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.title("CNN - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.show()

"""# Evaluation VGG16"""

plt.plot(history_vgg.history['accuracy'], label='Train Accuracy')
plt.plot(history_vgg.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('VGG16 - Accuracy')
plt.show()

plt.plot(history_vgg.history['loss'], label='Train Loss', color='red')
plt.plot(history_vgg.history['val_loss'], label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('VGG16 - Loss')
plt.show()

y_pred = model_vgg.predict(X_val)
y_pred_labels = (y_pred > 0.5).astype(int)

print("VGG16 - Classification Report:")
print(classification_report(y_val, y_pred_labels))

cm = confusion_matrix(y_val, y_pred_labels)
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
plt.title("VGG16 - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

fpr, tpr, _ = roc_curve(y_val, y_pred)
auc = roc_auc_score(y_val, y_pred)
print(f"VGG16 AUC: {auc:.4f}")
plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.title("VGG16 - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.show()

"""# Ecaluation MobileNetV2"""

plt.plot(history_mobilenet.history['accuracy'], label='Train Accuracy')
plt.plot(history_mobilenet.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('MobileNetV2 - Accuracy')
plt.show()

plt.plot(history_mobilenet.history['loss'], label='Train Loss', color='red')
plt.plot(history_mobilenet.history['val_loss'], label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('MobileNetV2 - Loss')
plt.show()

y_pred = model_mobilenet.predict(X_val)
y_pred_labels = (y_pred > 0.5).astype(int)

print("MobileNetV2 - Classification Report:")
print(classification_report(y_val, y_pred_labels))

cm = confusion_matrix(y_val, y_pred_labels)
sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')
plt.title("MobileNetV2 - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

fpr, tpr, _ = roc_curve(y_val, y_pred)
auc = roc_auc_score(y_val, y_pred)
print(f"MobileNetV2 AUC: {auc:.4f}")
plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.title("MobileNetV2 - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.show()

"""# Fine-Tune CNN"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Re-compile the model
model_cnn.compile(
    optimizer=Adam(learning_rate=1e-5),  # fine-tuning learning rate
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Early stopping
early_stop_cnn_ft = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

# re-train (fine-tuning)
history_cnn_ft = model_cnn.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32,
    callbacks=[early_stop_cnn_ft]
)

# Evaluation
val_loss, val_acc = model_cnn.evaluate(X_val, y_val)
print(f"Validation Loss (CNN Fine-Tuned): {val_loss:.4f}")
print(f"Validation Accuracy (CNN Fine-Tuned): {val_acc:.4f}")

test_loss, test_acc = model_cnn.evaluate(X_test, y_test)
print(f"Test Accuracy (CNN Fine-Tuned): {test_acc:.4f}")
print(f"Test Loss (CNN Fine-Tuned): {test_loss:.4f}")

"""# Fine-Tune VGG16"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

# Extract the base model from the first layer of the Sequential model
base_model_vgg = model_vgg.layers[0]
base_model_vgg.trainable = True  # Enable training on the base model

# Freeze all layers except the last 16 (about 4 convolutional blocks)
for layer in base_model_vgg.layers[:-16]:
    layer.trainable = False

# Re-compile the model with a lower learning rate for fine-tuning
model_vgg.compile(
    optimizer=Adam(learning_rate=1e-6),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# Define EarlyStopping to avoid overfitting
early_stop_vgg_ft = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)

# Fine-tune the model
history_vgg_ft = model_vgg.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=20,
    batch_size=32,
    callbacks=[early_stop_vgg_ft]
)

# Evaluate on validation set
val_loss, val_acc = model_vgg.evaluate(X_val, y_val)
print(f"Validation Loss (VGG16 Fine-Tuned): {val_loss:.4f}")
print(f"Validation Accuracy (VGG16 Fine-Tuned): {val_acc:.4f}")

# Evaluate on test set
test_loss, test_acc = model_vgg.evaluate(X_test, y_test)
print(f"Test Accuracy (VGG16 Fine-Tuned): {test_acc:.4f}")
print(f"Test Loss (VGG16 Fine-Tuned): {test_loss:.4f}")

"""# Fine-Tune MobileNetV2"""

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import models, layers, optimizers
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.utils import class_weight

# Unfreeze more layers from MobileNetV2
base_model_mobilenet = model_mobilenet.layers[0]
base_model_mobilenet.trainable = True

# Freeze only the first ~80 layers, unfreeze the rest
for layer in base_model_mobilenet.layers[:80]:
    layer.trainable = False

# Recompile with smaller learning rate
model_mobilenet.compile(
    optimizer=optimizers.Adam(learning_rate=5e-7),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# More aggressive early stopping
early_stop_better = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True
)

# Re-train the model
history_mobilenet_ft2 = model_mobilenet.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=25,
    batch_size=32,
    callbacks=[early_stop_better]
)

# Evaluate
val_loss, val_acc = model_mobilenet.evaluate(X_val, y_val)
print(f"Validation Loss (MobileNetV2 Improved): {val_loss:.4f}")
print(f"Validation Accuracy (MobileNetV2 Improved): {val_acc:.4f}")

test_loss, test_acc = model_mobilenet.evaluate(X_test, y_test)
print(f"Test Accuracy (MobileNetV2 Improved): {test_acc:.4f}")
print(f"Test Loss (MobileNetV2 Improved): {test_loss:.4f}")

"""# KFold Fine-Tuned CNN"""

from sklearn.model_selection import KFold
from tensorflow.keras.models import clone_model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
import numpy as np


cnn_fold_accuracies = []

kf = KFold(n_splits=5, shuffle=True, random_state=42)
fold = 1

for train_idx, val_idx in kf.split(X):
    print(f"\n--- Fold {fold} ---")

    X_train_k, X_val_k = X[train_idx], X[val_idx]
    y_train_k, y_val_k = y[train_idx], y[val_idx]

    # Clone the fine-tuned CNN
    model = clone_model(model_cnn)
    model.set_weights(model_cnn.get_weights())  # Use fine-tuned weights

    model.compile(
        optimizer=Adam(learning_rate=1e-5),  # same as fine-tuning
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)

    model.fit(
        X_train_k, y_train_k,
        validation_data=(X_val_k, y_val_k),
        epochs=20,
        batch_size=32,
        callbacks=[early_stop],
        verbose=0
    )

    val_loss, val_acc = model.evaluate(X_val_k, y_val_k, verbose=0)
    print(f"Validation Accuracy: {val_acc:.4f}")
    cnn_fold_accuracies.append(val_acc)

    K.clear_session()
    del model
    fold += 1

print(f"\nFinal CNN Fine-Tuned K-Fold Accuracy: {np.mean(cnn_fold_accuracies):.4f} ± {np.std(cnn_fold_accuracies):.4f}")

"""# KFold Fine-Tuned VGG16"""

from sklearn.model_selection import KFold
from tensorflow.keras.models import clone_model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import backend as K
import numpy as np

# Store accuracy per fold
vgg16_fold_accuracies = []

# Create splitter
kf = KFold(n_splits=5, shuffle=True, random_state=42)

fold = 1
for train_idx, val_idx in kf.split(X):
    print(f"\n--- Fold {fold} ---")

    X_train_k, X_val_k = X[train_idx], X[val_idx]
    y_train_k, y_val_k = y[train_idx], y[val_idx]

    # Clone fine-tuned model and reuse weights
    model = clone_model(model_vgg)
    model.set_weights(model_vgg.get_weights())  # Use fine-tuned weights

    # Compile
    model.compile(
        optimizer=Adam(learning_rate=1e-6),  # same as used in fine-tuning
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    # Early stopping
    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)

    # Train
    model.fit(
        X_train_k, y_train_k,
        validation_data=(X_val_k, y_val_k),
        epochs=20,
        batch_size=32,
        callbacks=[early_stop],
        verbose=0
    )

    # Evaluate
    val_loss, val_acc = model.evaluate(X_val_k, y_val_k, verbose=0)
    print(f"Validation Accuracy: {val_acc:.4f}")
    vgg16_fold_accuracies.append(val_acc)

    # Clear memory
    K.clear_session()
    del model
    fold += 1

# Final K-Fold results
mean_vgg16 = np.mean(vgg16_fold_accuracies)
std_vgg16 = np.std(vgg16_fold_accuracies)
print(f"\nFinal VGG16 Fine-Tuned K-Fold Accuracy: {mean_vgg16:.4f} ± {std_vgg16:.4f}")

"""# KFold Fine-Tuned MobileNetV2"""

mobilenet_fold_accuracies = []

kf = KFold(n_splits=5, shuffle=True, random_state=42)
fold = 1

for train_idx, val_idx in kf.split(X):
    print(f"\n--- Fold {fold} ---")

    X_train_k, X_val_k = X[train_idx], X[val_idx]
    y_train_k, y_val_k = y[train_idx], y[val_idx]

    model = clone_model(model_mobilenet)
    model.set_weights(model_mobilenet.get_weights())  # fine-tuned weights

    model.compile(
        optimizer=Adam(learning_rate=5e-7),  # same LR used in final tuning
        loss='binary_crossentropy',
        metrics=['accuracy']
    )

    early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)

    model.fit(
        X_train_k, y_train_k,
        validation_data=(X_val_k, y_val_k),
        epochs=20,
        batch_size=32,
        callbacks=[early_stop],
        verbose=0
    )

    val_loss, val_acc = model.evaluate(X_val_k, y_val_k, verbose=0)
    print(f"Validation Accuracy: {val_acc:.4f}")
    mobilenet_fold_accuracies.append(val_acc)

    K.clear_session()
    del model
    fold += 1

mean_mobile = np.mean(mobilenet_fold_accuracies)
std_mobile = np.std(mobilenet_fold_accuracies)
print(f"\nFinal MobileNetV2 Fine-Tuned K-Fold Accuracy: {mean_mobile:.4f} ± {std_mobile:.4f}")

"""# Evaluation Fine-Tuned CNN"""

# CNN Accuracy & Loss
plt.plot(history_cnn.history['accuracy'], label='Train Accuracy')
plt.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('CNN - Accuracy')
plt.show()

plt.plot(history_cnn.history['loss'], label='Train Loss', color='red')
plt.plot(history_cnn.history['val_loss'], label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('CNN - Loss')
plt.show()

# CNN Predictions
y_pred_cnn = model_cnn.predict(X_val)
y_pred_labels_cnn = (y_pred_cnn > 0.5).astype(int)

print("CNN - Classification Report:")
print(classification_report(y_val, y_pred_labels_cnn))

cm_cnn = confusion_matrix(y_val, y_pred_labels_cnn)
sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues')
plt.title("CNN - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

fpr_cnn, tpr_cnn, _ = roc_curve(y_val, y_pred_cnn)
auc_cnn = roc_auc_score(y_val, y_pred_cnn)
print(f"CNN AUC: {auc_cnn:.4f}")
plt.plot(fpr_cnn, tpr_cnn, label=f'AUC = {auc_cnn:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.title("CNN - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.show()

"""# Evaluation Fine-Tuned VGG16"""

# VGG16 Accuracy & Loss
plt.plot(history_vgg.history['accuracy'], label='Train Accuracy')
plt.plot(history_vgg.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('VGG16 - Accuracy')
plt.show()

plt.plot(history_vgg.history['loss'], label='Train Loss', color='red')
plt.plot(history_vgg.history['val_loss'], label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('VGG16 - Loss')
plt.show()

# VGG16 Predictions
y_pred_vgg = model_vgg.predict(X_val)
y_pred_labels_vgg = (y_pred_vgg > 0.5).astype(int)

print("VGG16 - Classification Report:")
print(classification_report(y_val, y_pred_labels_vgg))

cm_vgg = confusion_matrix(y_val, y_pred_labels_vgg)
sns.heatmap(cm_vgg, annot=True, fmt='d', cmap='Blues')
plt.title("VGG16 - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

fpr_vgg, tpr_vgg, _ = roc_curve(y_val, y_pred_vgg)
auc_vgg = roc_auc_score(y_val, y_pred_vgg)
print(f"VGG16 AUC: {auc_vgg:.4f}")
plt.plot(fpr_vgg, tpr_vgg, label=f'AUC = {auc_vgg:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.title("VGG16 - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.show()

"""# Evaluation Fine-Tuned MobileNetV2"""

# MobileNetV2 Accuracy & Loss
plt.plot(history_mobilenet.history['accuracy'], label='Train Accuracy')
plt.plot(history_mobilenet.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('MobileNetV2 - Accuracy')
plt.show()

plt.plot(history_mobilenet.history['loss'], label='Train Loss', color='red')
plt.plot(history_mobilenet.history['val_loss'], label='Validation Loss', color='blue')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('MobileNetV2 - Loss')
plt.show()

# MobileNetV2 Predictions
y_pred_mobile = model_mobilenet.predict(X_val)
y_pred_labels_mobile = (y_pred_mobile > 0.5).astype(int)

print("MobileNetV2 - Classification Report:")
print(classification_report(y_val, y_pred_labels_mobile))

cm_mobile = confusion_matrix(y_val, y_pred_labels_mobile)
sns.heatmap(cm_mobile, annot=True, fmt='d', cmap='Blues')
plt.title("MobileNetV2 - Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

fpr_mobile, tpr_mobile, _ = roc_curve(y_val, y_pred_mobile)
auc_mobile = roc_auc_score(y_val, y_pred_mobile)
print(f"MobileNetV2 AUC: {auc_mobile:.4f}")
plt.plot(fpr_mobile, tpr_mobile, label=f'AUC = {auc_mobile:.2f}')
plt.plot([0,1], [0,1], 'k--')
plt.title("MobileNetV2 - ROC Curve")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.grid()
plt.show()

"""# Chapter 5: Model Evaluation and Comparative Analysis"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import kruskal

# Step 1: Model performance scores (collected from earlier evaluation)
data = {
    "Model": ["CNN", "VGG16", "MobileNetV2"],
    "Accuracy": [0.98, 0.95, 0.92],
    "F1_Score": [0.98, 0.95, 0.92],
    "Avg_Recall": [0.985, 0.95, 0.915]
}
df = pd.DataFrame(data)

# Step 2: Display performance table
print("Model Performance Summary:")
print(df)

# Step 3: Bar Chart Comparison
metrics = ["Accuracy", "F1_Score", "Avg_Recall"]
x = range(len(metrics))
width = 0.25

plt.figure(figsize=(10, 6))
plt.bar([p - width for p in x], df.iloc[0, 1:], width=width, label='CNN')
plt.bar(x, df.iloc[1, 1:], width=width, label='VGG16')
plt.bar([p + width for p in x], df.iloc[2, 1:], width=width, label='MobileNetV2')
plt.xticks(x, metrics)
plt.ylim(0.85, 1.0)
plt.ylabel('Score')
plt.title('Model Comparison (Accuracy, F1, Recall)')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# Step 4: Boxplot Comparison
df_melted = pd.melt(df, id_vars="Model", var_name="Metric", value_name="Score")
plt.figure(figsize=(10, 6))
sns.boxplot(x="Metric", y="Score", hue="Model", data=df_melted)
plt.title("Boxplot of Model Performance Across Metrics")
plt.grid(True, linestyle='--', alpha=0.5)
plt.tight_layout()
plt.show()

# Step 5: Kruskal-Wallis Test (non-parametric ANOVA)
cnn_scores = [0.98, 0.98, 0.985]
vgg_scores = [0.95, 0.95, 0.95]
mobilenet_scores = [0.92, 0.92, 0.915]

stat, p_value = kruskal(cnn_scores, vgg_scores, mobilenet_scores)

# Step 6: Interpretation as a student
print("\nKruskal-Wallis H Test Result:")
print(f"Statistic = {stat:.4f}, p-value = {p_value:.4f}")

print("\n--- Student-style Interpretation ---")
if p_value < 0.05:
    print("Based on the p-value, we reject the null hypothesis.")
    print("This means that at least one of the models performs significantly different compared to the others.")
else:
    print("We fail to reject the null hypothesis.")
    print("This suggests that there is no statistically significant difference in performance between the models.")

print("\nFrom the charts and metric values, it is clear that the CNN model consistently performs better than both VGG16 and MobileNetV2 across all metrics (Accuracy, F1-Score, and Average Recall).")
print("Therefore, CNN can be considered the best model among the three for glaucoma detection.")

"""# Architectures"""

!pip install graphviz

from graphviz import Digraph

# Visualizing a simple custom CNN architecture
cnn = Digraph(comment='Custom CNN Architecture', format='png')
cnn.attr(rankdir='LR')  # left-to-right flow
cnn.attr('node', shape='box')

# Add CNN layers
cnn.node('Input', 'Input Image\n(224x224x3)')
cnn.node('Conv1', 'Conv2D (32)\nReLU')
cnn.node('Pool1', 'MaxPooling2D')
cnn.node('Conv2', 'Conv2D (64)\nReLU')
cnn.node('Pool2', 'MaxPooling2D')
cnn.node('Flatten', 'Flatten')
cnn.node('Dense1', 'Dense(128)\nReLU')
cnn.node('Output', 'Output Layer\nSigmoid')

# Define connections
cnn.edges([
    ('Input', 'Conv1'), ('Conv1', 'Pool1'),
    ('Pool1', 'Conv2'), ('Conv2', 'Pool2'),
    ('Pool2', 'Flatten'), ('Flatten', 'Dense1'),
    ('Dense1', 'Output')
])

# Save diagram as PNG
cnn.render('cnn_architecture', cleanup=True)
cnn

from graphviz import Digraph

# Basic VGG16 transfer learning structure
vgg = Digraph(comment='VGG16 Architecture (initial)', format='png')
vgg.attr(rankdir='LR')
vgg.attr('node', shape='box')

# VGG16 backbone with custom classifier
vgg.node('Input', 'Input Image\n(224x224x3)')
vgg.node('VGGBase', 'VGG16 Base\n(pretrained, frozen)')
vgg.node('GlobalAvgPool', 'GlobalAveragePooling2D')
vgg.node('Dense', 'Dense(128)\nReLU')
vgg.node('Output', 'Output Layer\nSigmoid')

vgg.edges([
    ('Input', 'VGGBase'),
    ('VGGBase', 'GlobalAvgPool'),
    ('GlobalAvgPool', 'Dense'),
    ('Dense', 'Output')
])

vgg.render('vgg16_architecture', cleanup=True)
vgg

from graphviz import Digraph

# MobileNetV2 base + classifier (before fine-tuning)
mobilenet = Digraph(comment='MobileNetV2 Architecture (initial)', format='png')
mobilenet.attr(rankdir='LR')
mobilenet.attr('node', shape='box')

mobilenet.node('Input', 'Input Image\n(224x224x3)')
mobilenet.node('MobileBase', 'MobileNetV2 Base\n(pretrained, frozen)')
mobilenet.node('GlobalPool', 'GlobalAveragePooling2D')
mobilenet.node('Dense', 'Dense(128)\nReLU')
mobilenet.node('Output', 'Output Layer\nSigmoid')

mobilenet.edges([
    ('Input', 'MobileBase'),
    ('MobileBase', 'GlobalPool'),
    ('GlobalPool', 'Dense'),
    ('Dense', 'Output')
])

mobilenet.render('mobilenetv2_architecture', cleanup=True)
mobilenet

from graphviz import Digraph

cnn_ft = Digraph(comment='Fine-tuned Custom CNN', format='png')
cnn_ft.attr(rankdir='LR')  # left-to-right layout
cnn_ft.attr('node', shape='box')

# Define layers after fine-tuning
cnn_ft.node('Input', 'Input Image\n(224x224x3)')
cnn_ft.node('Conv1', 'Conv2D (32)\nReLU')
cnn_ft.node('Pool1', 'MaxPooling')
cnn_ft.node('Conv2', 'Conv2D (64)\nReLU')
cnn_ft.node('Pool2', 'MaxPooling')
cnn_ft.node('Conv3', 'Conv2D (128)\nReLU')
cnn_ft.node('Pool3', 'MaxPooling')
cnn_ft.node('Flatten', 'Flatten')
cnn_ft.node('Dense1', 'Dense(128)\nReLU')
cnn_ft.node('Dropout', 'Dropout(0.5)')
cnn_ft.node('Dense2', 'Dense(64)\nReLU')  #  Fine-tuned layer
cnn_ft.node('Output', 'Output\nSigmoid')

cnn_ft.edges([
    ('Input','Conv1'), ('Conv1','Pool1'),
    ('Pool1','Conv2'), ('Conv2','Pool2'),
    ('Pool2','Conv3'), ('Conv3','Pool3'),
    ('Pool3','Flatten'), ('Flatten','Dense1'),
    ('Dense1','Dropout'), ('Dropout','Dense2'),
    ('Dense2','Output')
])

cnn_ft.render('fine_tuned_cnn', cleanup=True)
cnn_ft

from graphviz import Digraph

vgg16_ft = Digraph(comment='Fine-tuned VGG16', format='png')
vgg16_ft.attr(rankdir='LR')
vgg16_ft.attr('node', shape='box')

vgg16_ft.node('Input', 'Input Image\n(224x224x3)')
vgg16_ft.node('VGGBase', 'VGG16 Base\n(unfrozen for fine-tuning)')
vgg16_ft.node('GlobalAvgPool', 'GlobalAveragePooling2D')
vgg16_ft.node('Dense1', 'Dense(128)\nReLU')
vgg16_ft.node('Dropout', 'Dropout(0.5)')
vgg16_ft.node('Dense2', 'Dense(64)\nReLU')  #  Extra layer during fine-tuning
vgg16_ft.node('Output', 'Output\nSigmoid')

vgg16_ft.edges([
    ('Input', 'VGGBase'),
    ('VGGBase', 'GlobalAvgPool'),
    ('GlobalAvgPool', 'Dense1'),
    ('Dense1', 'Dropout'),
    ('Dropout', 'Dense2'),
    ('Dense2', 'Output')
])

vgg16_ft.render('fine_tuned_vgg16', cleanup=True)
vgg16_ft

from graphviz import Digraph

mobilenet_ft = Digraph(comment='Fine-tuned MobileNetV2', format='png')
mobilenet_ft.attr(rankdir='LR')
mobilenet_ft.attr('node', shape='box')

mobilenet_ft.node('Input', 'Input Image\n(224x224x3)')
mobilenet_ft.node('MobileBase', 'MobileNetV2 Base\n(unfrozen for fine-tuning)')
mobilenet_ft.node('GlobalPool', 'GlobalAveragePooling2D')
mobilenet_ft.node('Dense1', 'Dense(128)\nReLU')
mobilenet_ft.node('Dropout', 'Dropout(0.5)')
mobilenet_ft.node('Dense2', 'Dense(64)\nReLU')  #  Fine-tuned layer
mobilenet_ft.node('Output', 'Output\nSigmoid')

mobilenet_ft.edges([
    ('Input', 'MobileBase'),
    ('MobileBase', 'GlobalPool'),
    ('GlobalPool', 'Dense1'),
    ('Dense1', 'Dropout'),
    ('Dropout', 'Dense2'),
    ('Dense2', 'Output')
])

mobilenet_ft.render('fine_tuned_mobilenetv2', cleanup=True)
mobilenet_ft

"""# Flowchart Creation"""

# Import required libraries
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches

# Set up the plot area
fig, ax = plt.subplots(figsize=(10, 12))
ax.set_xlim(0, 10)
ax.set_ylim(0, 12)
ax.axis('off')  # Hide axis

# Define the steps and their positions
steps = [
    ("Start", (5, 11), 'ellipse'),
    ("Load Dataset\n(299 Glaucoma, 299 Normal)", (5, 10), 'box'),
    ("Preprocess Data\n(Resize, Normalize)", (5, 9), 'box'),
    ("Split Data\n(Train, Val, Test)", (5, 8), 'box'),
    ("Train Models\n(Custom CNN, VGG16, MobileNetV2)", (5, 7), 'box'),
    ("Evaluate Models\n(Metrics, Confusion Matrix)", (5, 6), 'box'),
    ("Fine-tune Models\n(VGG16, MobileNetV2)", (5, 5), 'box'),
    ("Evaluate Again\n(Post Fine-tuning)", (5, 4), 'box'),
    ("K-Fold Validation", (5, 3), 'box'),
    ("Compare Results", (5, 2), 'box'),
    ("End", (5, 1), 'ellipse')
]

# Draw each step
for text, (x, y), shape in steps:
    if shape == 'box':
        ax.add_patch(mpatches.FancyBboxPatch((x - 2.5, y - 0.4), 5, 0.8,
                      boxstyle="round,pad=0.02", edgecolor='black', facecolor='lightblue'))
    elif shape == 'ellipse':
        ax.add_patch(plt.Circle((x, y), 0.6, edgecolor='black', facecolor='lightgreen'))
    ax.text(x, y, text, ha='center', va='center', fontsize=10)

# Connect steps with arrows
for i in range(len(steps) - 1):
    x1, y1 = steps[i][1]
    x2, y2 = steps[i + 1][1]
    ax.annotate('', xy=(x2, y2 + 0.4), xytext=(x1, y1 - 0.4),
                arrowprops=dict(arrowstyle='->', lw=1.5))

# Save the flowchart as a PNG image
plt.tight_layout()
plt.savefig("final_flowchart.png")